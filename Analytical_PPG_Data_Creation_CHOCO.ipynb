{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "\n",
    "#################Data Prep and Combined#####################\n",
    "#Nielsen Info (Sales, units,ACV(dist), Median base price, final base price, tpr & SI)\n",
    "#Retailer Info (Retailer Units-from raw data and Apportion)\n",
    "#Price Monitoring Info (Price, median base price)\n",
    "#Promo Info (Promo Period, promo days, discount)\n",
    "#Catalog & Hyperocm Info\n",
    "# Display Info\n",
    "#Holiday Info\n",
    "#Nielsen PPG-Competitors Picre Info\n",
    "\n",
    "#path=\"C:\\\\Users\\\\omprakash.bankol\\\\Desktop\\MARS_Russia\\\\Dataset Preparation\\\\\"\n",
    "path=\"..\\\\Process\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omprakash.bankol\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\lib\\nanfunctions.py:1116: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input=overwrite_input)\n"
     ]
    }
   ],
   "source": [
    "### Reading apportioned weekly sales data along with Nielsen info\n",
    "sales_data =pd.read_excel(path+\"\\\\Analytical_Output_Optimizer\\\\Nielsen_POS_Data_Apportioned_CHOCO.xlsx\")\n",
    "sales_data=sales_data.loc[sales_data['Year']> 2017,]\n",
    "sales_data.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#Drop uncommon PPG part data (SKU)\n",
    "sales_data['PPG_Part_Common']=sales_data['PPG_Part'].apply(lambda x: not(\"Out_Any\" in x) )\n",
    "sales_data =sales_data.loc[sales_data['PPG_Part_Common'],]\n",
    "sales_data.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#Nielsen updated units\n",
    "sales_data['PPG_Part_in_Magnit']=sales_data['PPG_Part'].apply(lambda x: (\"In_Magnit\" in x) )\n",
    "var=\"Nielsen_Updated_Units\"\n",
    "sales_data.loc[sales_data['PPG_Part_in_Magnit'],var] = sales_data.loc[sales_data['PPG_Part_in_Magnit'],'Nielsen_Units']\n",
    "\n",
    "\n",
    "#rolled up\n",
    "col_group=['Manufacturer', 'PPG', 'Date', 'Year', 'Month', 'Week_no']\n",
    "sales_data_sum=sales_data.groupby(col_group)['Nielsen_Units', 'Nielsen_Sales', 'Nielsen_Volume','Nielsen_Updated_Units',\n",
    "                  'X5_Units_Weekly','Magnit_Units_Weekly','X5_Units_Monthly', 'X5_LSV_Monthly', 'Magnit_Units_Monthly',\n",
    "                  'Magnit_Sales_Monthly', 'Magnit_LSV_Monthly'].sum().reset_index()\n",
    "\n",
    "sales_data_max = sales_data.groupby(col_group)['Nielsen_Numeric_dist', 'Nielsen_Weighted_dist'].max().reset_index()\n",
    "sales_data0 = pd.merge(sales_data_sum,sales_data_max,on=col_group,how='left')\n",
    "\n",
    "del sales_data\n",
    "sales_data=sales_data0.copy()\n",
    "\n",
    "\n",
    "#wide to long\n",
    "Retailer_sales_data =sales_data[['Date','PPG','Magnit_Units_Weekly','X5_Units_Weekly']]\n",
    "Retailer_sales_data_long=pd.melt(Retailer_sales_data,id_vars=['Date','PPG'],var_name=\"Retailer\",value_name='Retailer_Units')\n",
    "Retailer_sales_data_long['Retailer']=Retailer_sales_data_long['Retailer'].map({'Magnit_Units_Weekly': 'Magnit', 'X5_Units_Weekly': 'X5'})\n",
    "\n",
    "col_drop=['Magnit_Units_Weekly','X5_Units_Weekly','X5_Units_Monthly', 'X5_LSV_Monthly','Magnit_Units_Monthly', 'Magnit_Sales_Monthly', 'Magnit_LSV_Monthly']\n",
    "sales_data.drop(col_drop,axis=1,inplace=True)\n",
    "\n",
    "#Merge Nielsen and POS data\n",
    "sales_data1 = pd.merge(sales_data,Retailer_sales_data_long,on=['PPG','Date'],how='left')\n",
    "\n",
    "\n",
    "#reorder\n",
    "move_col = sales_data1['Retailer']\n",
    "sales_data1.drop(labels=['Retailer'], axis=1, inplace = True)\n",
    "sales_data1.insert(2, 'Retailer', move_col)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######Nielsen Median Base Price Calculation######\n",
    "sales_data1.sort_values(['Manufacturer','Retailer','PPG','Date'], axis = 0, ascending = True,inplace = True)\n",
    "sales_data1.reset_index(drop=True,inplace=True)\n",
    "sales_data1['Nielsen_price_per_unit']=sales_data1['Nielsen_Sales']/sales_data1['Nielsen_Units']\n",
    "\n",
    "for i in range(1,8):\n",
    "    sales_data1['Nielsen_price_per_unit'+'_lag'+str(i)]=sales_data1.groupby(['Retailer','PPG'])['Nielsen_price_per_unit'].shift(periods=i)\n",
    "\n",
    "#max of previous 7 weeks\n",
    "Cols_Nielsen = [i for i in list(sales_data1.columns) if \"Nielsen_price_per_unit_lag\" in i] \n",
    "sales_data1['Nielsen_max_price_prev']=  sales_data1[Cols_Nielsen].max(axis=1)  \n",
    "\n",
    "\n",
    "#sudden jump in price will map to NA\n",
    "for i in range(1,8):\n",
    "    var='Nielsen_price_per_unit'+'_lag'+str(i)\n",
    "    sales_data1.loc[np.abs(sales_data1[var]-sales_data1['Nielsen_max_price_prev'])/sales_data1['Nielsen_max_price_prev'] > 0.05,var]=np.nan\n",
    "\n",
    "\n",
    "#median base price\n",
    "sales_data1['Nielsen_median_base_price']=sales_data1[Cols_Nielsen].median(axis=1) \n",
    "sales_data1['Nielsen_median_base_price']=sales_data1['Nielsen_median_base_price']\n",
    "\n",
    "var='Nielsen_median_base_price'\n",
    "idx = np.where(np.abs(sales_data1[var]-sales_data1['Nielsen_price_per_unit'])/sales_data1[var] <= 0.05, 1, 0)\n",
    "sales_data1.loc[idx==1,var]=sales_data1.loc[idx==1,'Nielsen_price_per_unit']\n",
    "sales_data1.loc[idx==0,var]=sales_data1.loc[idx==0,var]\n",
    "\n",
    "\n",
    "#final base price (more smoother than median base)\n",
    "sales_data1.sort_values(['Retailer','PPG','Date'], axis = 0, ascending = True,inplace = True)\n",
    "sales_data1.index=sales_data1['Date']\n",
    "final_base_price=sales_data1.groupby(['Retailer','PPG'])[var].rolling(window=26,min_periods=1).max()\n",
    "final_base_price=pd.DataFrame(final_base_price)\n",
    "(final_base_price).reset_index(inplace=True)\n",
    "final_base_price.rename(columns={'Nielsen_median_base_price':'Nielsen_final_base_price'},inplace=True)\n",
    "sales_data1.reset_index(inplace=True,drop=True)\n",
    "sales_data1=pd.merge(sales_data1,final_base_price,on=['Retailer','PPG','Date'],how='left')\n",
    "\n",
    "#na in final base price, replace by asp\n",
    "idx = np.where(sales_data1['Nielsen_final_base_price'].isna(), 1, 0)\n",
    "sales_data1.loc[idx==1,'Nielsen_final_base_price']=sales_data1.loc[idx==1,'Nielsen_price_per_unit']\n",
    "\n",
    "\n",
    "#\n",
    "var='Nielsen_final_base_price'\n",
    "idx = np.where(np.abs(sales_data1[var]-sales_data1['Nielsen_median_base_price'])/sales_data1[var] >= 0.05, 1, 0)\n",
    "sales_data1.loc[idx==1,'Nielsen_median_base_price']=sales_data1.loc[idx==1,var]*0.95\n",
    "#sales_data1.loc[idx==0,'Nielsen_median_base_price']=sales_data1.loc[idx==0,'Nielsen_median_base_price']\n",
    "sales_data2=sales_data1.copy()\n",
    "Cols_Nielsen = [i for i in list(sales_data1.columns) if \"Nielsen_price_per_unit_lag\" in i] \n",
    "Cols_Nielsen=Cols_Nielsen+['Nielsen_max_price_prev']\n",
    "sales_data2.drop(Cols_Nielsen,axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X5        702\n",
       "Magnit    702\n",
       "Name: Retailer, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####Nielsen Combined() TPR calculation#####\n",
    "sales_data2['Nielsen_TPR']=0\n",
    "var='Nielsen_median_base_price'\n",
    "idx = np.where((sales_data2[var]-sales_data2['Nielsen_price_per_unit'])/sales_data2[var] > 0.05, 1, 0)\n",
    "sales_data2.loc[idx==1,'Nielsen_TPR']=(sales_data2[var]-sales_data2['Nielsen_price_per_unit'])/sales_data2[var]\n",
    "sales_data2['Nielsen_TPR']=sales_data2['Nielsen_TPR']*100\n",
    "#s\n",
    "\n",
    "sales_data2['PPG'].value_counts()\n",
    "sales_data2['Year'].value_counts()\n",
    "sales_data2['Retailer'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1404, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####SI merge (calculated on Segment)#####\n",
    "SI_data =pd.read_excel(path+\"\\\\SI_Index\\\\Bars_17_18 Seasonality Index.xlsx\")\n",
    "SI_data['week_number'] =\"W\"+SI_data['week_number'].astype(str)\n",
    "SI_data.rename(columns={'SI':'SI_17_18','week_number':'Week'},inplace=True)\n",
    "sales_data2.rename(columns={'Week_no':'Week'},inplace=True)\n",
    "sales_data2 = pd.merge(sales_data2,SI_data,on=\"Week\",how=\"left\")\n",
    "\n",
    "SI_data =pd.read_excel(path+\"\\\\SI_Index\\\\Bars_18_19 Seasonality Index.xlsx\")\n",
    "SI_data['week_number'] =\"W\"+SI_data['week_number'].astype(str)\n",
    "SI_data.rename(columns={'SI':'SI_18_19','week_number':'Week'},inplace=True)\n",
    "sales_data2.rename(columns={'Week_no':'Week'},inplace=True)\n",
    "sales_data2 = pd.merge(sales_data2,SI_data,on=\"Week\",how=\"left\")\n",
    "\n",
    "SI_data =pd.read_excel(path+\"\\\\SI_Index\\\\Bars_17_18_19 Seasonality Index.xlsx\")\n",
    "SI_data['week_number'] =\"W\"+SI_data['week_number'].astype(str)\n",
    "SI_data.rename(columns={'SI':'SI_17_18_19','week_number':'Week'},inplace=True)\n",
    "sales_data2.rename(columns={'Week_no':'Week'},inplace=True)\n",
    "sales_data2 = pd.merge(sales_data2,SI_data,on=\"Week\",how=\"left\")\n",
    "\n",
    "sales_data2.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Manufacturer', 'PPG', 'Retailer', 'Date', 'Year', 'Month', 'Week',\n",
       "       'Nielsen_Units', 'Nielsen_Sales', 'Nielsen_Volume',\n",
       "       'Nielsen_Updated_Units', 'Nielsen_Numeric_dist',\n",
       "       'Nielsen_Weighted_dist', 'Retailer_Units', 'Nielsen_price_per_unit',\n",
       "       'Nielsen_median_base_price', 'Nielsen_final_base_price', 'Nielsen_TPR',\n",
       "       'SI_17_18', 'SI_18_19', 'SI_17_18_19'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Price Monitoring#####\n",
    "#APM=Average price monitoring, WPM=Weighted Price Monitoring\n",
    "price_monitor =pd.read_excel(path+\"\\\\Price_Monitoring\\\\Price_Monitoring_PPG_Data.xlsx\")\n",
    "price_monitor.columns\n",
    "price_monitor.drop(['Nielsen_Units', 'PricexUnit'],axis=1,inplace=True)\n",
    "sales_data2 = pd.merge(sales_data2,price_monitor,on=['Retailer','PPG','Date'],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1404, 39)\n"
     ]
    }
   ],
   "source": [
    "#######Promo Information##########\n",
    "promo_data =pd.read_excel(path+\"\\\\Promo\\\\Weekly_Promo_Choco_Data(PPG_Level).xlsx\")\n",
    "promo_data.rename(columns={'Week.Start.date':'Date','PPG Name':'PPG'},inplace=True)\n",
    "promo_data['Retailer'].value_counts()\n",
    "#promo_data['Retailer']=promo_data['Retailer'].map({'Магнит':'Magnit','Пятерочка':'X5'})\n",
    "promo_data['PPG'].value_counts()\n",
    "col_del=['Year','Week','Month_Name','Month']\n",
    "promo_data.drop(col_del,axis=1,inplace=True)\n",
    "sales_data2=pd.merge(sales_data2,promo_data,on=['Retailer','PPG','Date'],how='left')\n",
    "print(sales_data2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1404, 53)\n",
      "(1404, 58)\n"
     ]
    }
   ],
   "source": [
    "#######Catalog Information and Hyperocm Info###########\n",
    "#is promo days same as promo_data, take PPG names\n",
    "catalog_data =pd.read_excel(path+\"\\\\HypercomAndDisplay\\\\Weekly_Promo_hypercom_choco_Data(PPG_Level).xlsx\")\n",
    "catalog_data.rename(columns={'Seller':'Retailer','Promo Group':'PPG'},inplace=True)\n",
    "catalog_data['Retailer'].value_counts()\n",
    "catalog_data['PPG'].value_counts()\n",
    "catalog_data.drop(['Year','Week', 'Month_Name', 'Month','promo_days'],axis=1,inplace=True)\n",
    "sales_data2=pd.merge(sales_data2,catalog_data,on=['Retailer','PPG','Date'],how='left')\n",
    "print(sales_data2.shape)\n",
    "\n",
    "#perfer hypercom dicount,\n",
    "sales_data2['Promo_Hyper_Discount']=sales_data2['Avg_Discount.depth']\n",
    "idx = np.where(sales_data2['Promo_Hyper_Discount'].isna(), 1, 0)\n",
    "sales_data2.loc[idx==1,'Promo_Hyper_Discount']=sales_data2.loc[idx==1,'Discount..NRV..']\n",
    "\n",
    "########Display Info############\n",
    "#is promo period same as we got in promo_data?\n",
    "display_data=pd.read_excel(path+\"\\\\HypercomAndDisplay\\\\Disply_Output_V1.xlsx\")\n",
    "display_data.rename(columns={'Week.Start.date':'Date','Promo_Group':'PPG','MWC Chain':'Retailer'},inplace=True)\n",
    "display_data['Retailer'].value_counts()\n",
    "display_data['Retailer']=display_data['Retailer'].map({'Магнит':'Magnit','Пятерочка':'X5'})\n",
    "display_data['PPG'].value_counts()\n",
    "col_req=['Date','BAHS','AHS', 'miniBAHS', 'miniAHS', 'PPG', 'Retailer']\n",
    "sales_data2=pd.merge(sales_data2,display_data[col_req],on=['Retailer','PPG','Date'],how='left')\n",
    "print(sales_data2.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Manufacturer', 'PPG', 'Retailer', 'Date', 'Year', 'Month', 'Week',\n",
       "       'Nielsen_Units', 'Nielsen_Sales', 'Nielsen_Volume',\n",
       "       'Nielsen_Updated_Units', 'Nielsen_Numeric_dist',\n",
       "       'Nielsen_Weighted_dist', 'Retailer_Units', 'Nielsen_price_per_unit',\n",
       "       'Nielsen_median_base_price', 'Nielsen_final_base_price', 'Nielsen_TPR',\n",
       "       'SI_17_18', 'SI_18_19', 'SI_17_18_19', 'Avg_Price_Monitoring',\n",
       "       'Weighted_Price_Monitoring', 'WPM_median_base_price',\n",
       "       'WPM_final_base_price', 'APM_median_base_price', 'APM_final_base_price',\n",
       "       'Date start promo', 'Date end promo', 'Promo_days', 'Level',\n",
       "       'Activity.name', 'Mechanic', 'Discount..NRV..', 'Auto.Status.Promo',\n",
       "       'Manual.Status.Promo', 'Approved', 'Fact_Flag', 'Remark', 'start date',\n",
       "       'expiration date', 'sum_..Directory.distribution',\n",
       "       'Avg_..Directory.distribution', 'max_..Directory.distribution', 'Count',\n",
       "       'sum_Distribution.Promo.', 'Avg_Distribution.Promo.',\n",
       "       'Max_Distribution.Promo.', 'Avg_Price.without.stock.for.goods',\n",
       "       'Avg_Promo.Price', 'Avg_Price.per.unit', 'Avg_Virtual.price',\n",
       "       'Avg_Discount.depth', 'Promo_Hyper_Discount', 'BAHS', 'AHS', 'miniBAHS',\n",
       "       'miniAHS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete cols\n",
    "col_del=['sum_..Directory.distribution','Avg_..Directory.distribution','sum_Distribution.Promo.','Avg_Distribution.Promo.']\n",
    "sales_data2.drop(col_del,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Holdiay Flag Retailer#######\n",
    "magnit_holiday=pd.read_excel(path+\"\\\\Holiday\\\\Magnit Holiday Flag 18,19,20.xlsx\")\n",
    "x5_holiday=pd.read_excel(path+\"\\\\Holiday\\\\X5 Holiday Flag 18,19,20.xlsx\")\n",
    "magnit_holiday['Retailer']=\"Magnit\"\n",
    "x5_holiday[\"Retailer\"]= \"X5\"\n",
    "pos_holiday =pd.concat([x5_holiday,magnit_holiday], axis=0, ignore_index=True,sort=True)\n",
    "pos_holiday.rename(columns={'Week Start Date':'Date'},inplace=True)\n",
    "pos_holiday.drop(['Year','Week End Date','Week Number'],axis=1,inplace=True)\n",
    "pos_holiday.shape\n",
    "sales_data3=pd.merge(sales_data2,pos_holiday,on=['Retailer','Date'],how='left')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Nielsen PPG Competitors Information ########\n",
    "N_PPG_comp =pd.read_excel(path+\"\\\\Competitor\\\\Nielsen_PPG_Competitors_Data_CHOCO.xlsx\")\n",
    "N_PPG_comp.columns\n",
    "sales_data3 = pd.merge(sales_data3,N_PPG_comp,on=['PPG','Date'],how=\"left\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Manufacturer                                                   0\n",
       "PPG                                                            0\n",
       "Retailer                                                       0\n",
       "Date                                                           0\n",
       "Year                                                           0\n",
       "Month                                                          0\n",
       "Week                                                           0\n",
       "Nielsen_Units                                                  0\n",
       "Nielsen_Sales                                                  0\n",
       "Nielsen_Volume                                                 0\n",
       "Nielsen_Updated_Units                                          0\n",
       "Nielsen_Numeric_dist                                         520\n",
       "Nielsen_Weighted_dist                                        520\n",
       "Retailer_Units                                                 0\n",
       "Nielsen_price_per_unit                                       518\n",
       "Nielsen_median_base_price                                    528\n",
       "Nielsen_final_base_price                                     518\n",
       "Nielsen_TPR                                                    0\n",
       "SI_17_18                                                       0\n",
       "SI_18_19                                                       0\n",
       "SI_17_18_19                                                    0\n",
       "Avg_Price_Monitoring                                         569\n",
       "Weighted_Price_Monitoring                                    755\n",
       "WPM_median_base_price                                        763\n",
       "WPM_final_base_price                                         755\n",
       "APM_median_base_price                                        579\n",
       "APM_final_base_price                                         569\n",
       "Date start promo                                            1307\n",
       "Date end promo                                              1307\n",
       "Promo_days                                                   585\n",
       "                                                            ... \n",
       "NESTLE_NESQUIK.Nielsen_ASP                                   702\n",
       "NESTLE_NUTS.Nielsen_ASP                                      892\n",
       "NEVSKIY KONDITER/SPB.Nielsen_ASP                            1220\n",
       "OBYEDINYONNYE KONDITERY_ALYONKA.Nielsen_ASP                  936\n",
       "OBYEDINYONNYE KONDITERY_BABAEVSKIY.Nielsen_ASP               952\n",
       "OBYEDINYONNYE KONDITERY_KOROVKA.Nielsen_ASP                 1170\n",
       "OBYEDINYONNYE KONDITERY_PETERBURGSKIE TAYNY.Nielsen_ASP     1342\n",
       "OBYEDINYONNYE KONDITERY_SORMOVO.Nielsen_ASP                 1340\n",
       "ORKLA GROUP_LAIMA.Nielsen_ASP                                980\n",
       "ORKLA GROUP_MARTSIPAN.Nielsen_ASP                           1276\n",
       "ORKLA GROUP_VANA TALLIN.Nielsen_ASP                         1238\n",
       "OTHERS.Nielsen_ASP                                           730\n",
       "OTHERS_GRONDARD.Nielsen_ASP                                 1198\n",
       "OTHERS_KHIT.Nielsen_ASP                                     1006\n",
       "OTHERS_KISMET.Nielsen_ASP                                    996\n",
       "OTHERS_LUSETTE.Nielsen_ASP                                  1202\n",
       "OTHERS_MARIO & BIANCA.Nielsen_ASP                           1322\n",
       "OTHERS_MILK`S STORY.Nielsen_ASP                             1032\n",
       "OTHERS_OGO.Nielsen_ASP                                      1304\n",
       "OTHERS_SAVINOV.Nielsen_ASP                                  1024\n",
       "OTHERS_SPARTAK.Nielsen_ASP                                  1170\n",
       "OTHERS_STOLICHNYE SHTUCHKI.Nielsen_ASP                       936\n",
       "OTHERS_SWEET+PLUS.Nielsen_ASP                               1326\n",
       "OTHERS_VIT`BA.Nielsen_ASP                                   1356\n",
       "OTHERS_WAFF.Nielsen_ASP                                     1170\n",
       "OTHERS_ZENTIS.Nielsen_ASP                                    702\n",
       "SLAVYANKA GK/STARIY OSKOL.Nielsen_ASP                        942\n",
       "SLAVYANKA GK/STARIY OSKOL_OBYKNOVENNOE CHUDO.Nielsen_ASP     936\n",
       "SLAVYANKA GK/STARIY OSKOL_STEP.Nielsen_ASP                  1028\n",
       "STORCK/GERMANY.Nielsen_ASP                                  1308\n",
       "Length: 125, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove time stamp\n",
    "sales_data3['Date'] = pd.to_datetime(sales_data3['Date']).dt.date\n",
    "sales_data3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1404, 125)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove time stamp\n",
    "sales_data3['Date'] = pd.to_datetime(sales_data3['Date']).dt.date\n",
    "sales_data3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "sales_data3.to_excel(\"..\\\\Output\\\\Data_Prep_Analytical\\\\Analytical_Combined_Dataset_CHOCO.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
